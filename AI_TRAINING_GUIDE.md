# H∆∞·ªõng D·∫´n Train AI Models tr√™n Google Colab

## üìö T·ªïng Quan

B·∫°n c·∫ßn train 2 models:

1. **Toxic Detection** - Ph√°t hi·ªán spam, hate speech, harassment
2. **Emotion Detection** - Ph√°t hi·ªán 8 c·∫£m x√∫c

## üöÄ B∆∞·ªõc 1: Chu·∫©n B·ªã Dataset

### Toxic Detection Dataset

**Option 1: Download t·ª´ GitHub**

- Repo: https://github.com/bakansm/ViTHSD
- Download file CSV v·ªõi format:
  ```csv
  text,label
  "N·ªôi dung b√¨nh th∆∞·ªùng",clean
  "Spam content",spam
  "Hate speech",hate_speech
  "Qu·∫•y r·ªëi",harassment
  ```

**Option 2: T·ª± t·∫°o dataset**

- T·∫°o file `toxic_dataset.csv` v·ªõi 4 labels: clean, spam, hate_speech, harassment
- M·ªói label n√™n c√≥ √≠t nh·∫•t 500-1000 samples
- Upload l√™n Google Drive

### Emotion Detection Dataset

Dataset **ƒë√£ c√≥ s·∫µn** trong `ai/emotions/dataset/`:

- `train_nor_811.xlsx` - Training data
- `test_nor_811.xlsx` - Test data

Format:

```
text,emotion
"T√¥i r·∫•t vui",joy
"Bu·ªìn qu√°",sadness
```

8 emotions: joy, sadness, anger, fear, surprise, neutral, love, disgust

## üîß B∆∞·ªõc 2: Setup Google Colab

### 2.1. T·∫°o Notebook m·ªõi

1. V√†o https://colab.research.google.com
2. T·∫°o notebook m·ªõi
3. Ch·ªçn **Runtime** ‚Üí **Change runtime type** ‚Üí **GPU** (T4 ho·∫∑c cao h∆°n)

### 2.2. Mount Google Drive

```python
from google.colab import drive
drive.mount('/content/drive')
```

### 2.3. T·∫°o C·∫•u Tr√∫c Th∆∞ M·ª•c

```python
BASE_PATH = '/content/drive/MyDrive/DoAnHTTM/ai'

# T·∫°o th∆∞ m·ª•c
import os
os.makedirs(f'{BASE_PATH}/toxic_detection/dataset', exist_ok=True)
os.makedirs(f'{BASE_PATH}/toxic_detection/checkpoints', exist_ok=True)
os.makedirs(f'{BASE_PATH}/toxic_detection/logs', exist_ok=True)

os.makedirs(f'{BASE_PATH}/emotions/dataset', exist_ok=True)
os.makedirs(f'{BASE_PATH}/emotions/checkpoints', exist_ok=True)
os.makedirs(f'{BASE_PATH}/emotions/logs', exist_ok=True)
```

## üìù B∆∞·ªõc 3: Train Toxic Detection Model

### 3.1. Copy Code

Copy to√†n b·ªô code t·ª´ `ai/toxic_detection/train.py` v√†o Colab notebook.

### 3.2. Upload Dataset

Upload file `toxic_dataset.csv` v√†o:

```
/content/drive/MyDrive/DoAnHTTM/ai/toxic_detection/dataset/
```

### 3.3. Ch·∫°y Training

```python
# Ch·∫°y t·ª´ng cell theo th·ª© t·ª±
# Ho·∫∑c ch·∫°y to√†n b·ªô: Runtime ‚Üí Run all
```

**Th·ªùi gian training:**

- T4 GPU: ~2-3 gi·ªù (10 epochs)
- CPU: ~10-15 gi·ªù

**K·∫øt qu·∫£ mong ƒë·ª£i:**

- Training Accuracy: ~85-90%
- Validation F1: ~85-90%
- Test Accuracy: ~85-90%

### 3.4. Download Model

Sau khi train xong, model s·∫Ω l∆∞u t·∫°i:

```
/content/drive/MyDrive/DoAnHTTM/ai/toxic_detection/checkpoints/best_model.pt
```

Download v·ªÅ m√°y v√† ƒë·∫∑t v√†o:

```
DoAnHTTM/ai/toxic_detection/checkpoints/best_model.pt
```

## üé≠ B∆∞·ªõc 4: Train Emotion Detection Model

### 4.1. Copy Code

T∆∞∆°ng t·ª± nh∆∞ toxic detection, nh∆∞ng thay ƒë·ªïi:

```python
# Change num_classes
num_classes = 8  # Instead of 4

# Change labels
emotions = ['joy', 'sadness', 'anger', 'fear', 'surprise', 'neutral', 'love', 'disgust']
label2id = {label: i for i, label in enumerate(emotions)}
id2label = {i: label for i, label in enumerate(emotions)}

# Load from Excel instead of CSV
import pandas as pd
train_data = pd.read_excel(f'{BASE_PATH}/emotions/dataset/train_nor_811.xlsx')
test_data = pd.read_excel(f'{BASE_PATH}/emotions/dataset/test_nor_811.xlsx')
```

### 4.2. Upload Dataset

Upload 2 files Excel v√†o:

```
/content/drive/MyDrive/DoAnHTTM/ai/emotions/dataset/
```

### 4.3. Ch·∫°y Training

**Th·ªùi gian:** ~3-4 gi·ªù v·ªõi T4 GPU

**K·∫øt qu·∫£ mong ƒë·ª£i:**

- Training Accuracy: ~80-85%
- Validation F1: ~80-85%

### 4.4. Download Model

Download file `best_model.pt` v·ªÅ:

```
DoAnHTTM/ai/emotions/checkpoints/best_model.pt
```

## üß™ B∆∞·ªõc 5: Test Models

### Test Toxic Detection

```python
def predict_toxic(text, model, tokenizer, device):
    model.eval()
    encoding = tokenizer(text, max_length=256, padding='max_length',
                        truncation=True, return_tensors='pt')

    with torch.no_grad():
        outputs = model(encoding['input_ids'].to(device),
                       encoding['attention_mask'].to(device))
        probs = torch.softmax(outputs, dim=1)
        pred_class = torch.argmax(probs, dim=1).item()

    return {
        'label': id2label[pred_class],
        'confidence': probs[0][pred_class].item(),
        'is_toxic': id2label[pred_class] != 'clean'
    }

# Test
test_texts = [
    "B√†i vi·∫øt r·∫•t hay v√† b·ªï √≠ch!",
    "Spam spam spam",
    "Ng∆∞·ªùi n√†y ngu ng·ªëc qu√°"
]

for text in test_texts:
    result = predict_toxic(text, model, tokenizer, device)
    print(f"Text: {text}")
    print(f"Result: {result}\n")
```

### Test Emotion Detection

```python
def predict_emotion(text, model, tokenizer, device):
    # Similar to toxic detection
    ...

test_texts = [
    "H√¥m nay t√¥i r·∫•t vui!",
    "Bu·ªìn qu√°...",
    "T·ª©c gi·∫≠n qu√°!"
]

for text in test_texts:
    result = predict_emotion(text, model, tokenizer, device)
    print(f"Text: {text}")
    print(f"Emotion: {result['emotion']} (confidence: {result['confidence']:.2f})\n")
```

## üìä B∆∞·ªõc 6: Model Evaluation

### Confusion Matrix

```python
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Get predictions
y_true, y_pred = [], []
for batch in test_loader:
    outputs = model(batch['input_ids'].to(device),
                   batch['attention_mask'].to(device))
    preds = torch.argmax(outputs, dim=1)
    y_true.extend(batch['label'].tolist())
    y_pred.extend(preds.cpu().tolist())

# Plot
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=list(label2id.keys()),
            yticklabels=list(label2id.keys()))
plt.title('Confusion Matrix')
plt.ylabel('True')
plt.xlabel('Predicted')
plt.show()
```

## üîÑ B∆∞·ªõc 7: Deploy Models

### 7.1. Copy Models

Copy 2 files `best_model.pt` v·ªÅ m√°y local v√†o ƒë√∫ng th∆∞ m·ª•c:

```
DoAnHTTM/
‚îú‚îÄ‚îÄ ai/
‚îÇ   ‚îú‚îÄ‚îÄ toxic_detection/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ best_model.pt  ‚Üê Copy v√†o ƒë√¢y
‚îÇ   ‚îî‚îÄ‚îÄ emotions/
‚îÇ       ‚îî‚îÄ‚îÄ checkpoints/
‚îÇ           ‚îî‚îÄ‚îÄ best_model.pt  ‚Üê Copy v√†o ƒë√¢y
```

### 7.2. Update .env

```env
TOXIC_MODEL_PATH=./toxic_detection/checkpoints/best_model.pt
EMOTION_MODEL_PATH=./emotions/checkpoints/best_model.pt
```

### 7.3. Start AI Service

```bash
cd ai
python api.py
```

Test API:

```bash
curl -X POST http://localhost:8000/api/ai/toxic \
  -H "X-API-Key: your_api_key" \
  -H "Content-Type: application/json" \
  -d '{"text": "Test text"}'
```

## üí° Tips & Best Practices

### Training Tips

1. **Batch Size:**

   - T4 GPU: batch_size = 16-32
   - CPU: batch_size = 8-16
   - OOM error ‚Üí gi·∫£m batch size

2. **Learning Rate:**

   - Start v·ªõi 2e-5 (recommended for PhoBERT)
   - N·∫øu loss kh√¥ng gi·∫£m ‚Üí tƒÉng l√™n 3e-5 ho·∫∑c 5e-5

3. **Epochs:**

   - 10 epochs th∆∞·ªùng ƒë·ªß
   - N·∫øu val_loss tƒÉng s·ªõm ‚Üí c√≥ th·ªÉ gi·∫£m xu·ªëng 5-7 epochs

4. **Early Stopping:**
   - Implement n·∫øu val_loss kh√¥ng improve sau 3 epochs

### Data Augmentation

```python
# Back translation (d·ªãch qua l·∫°i)
# Synonym replacement
# Random insertion/deletion
# ...
```

### Model Optimization

**Quantization** (gi·∫£m model size):

```python
import torch.quantization as quantization

# Dynamic quantization
model_quantized = quantization.quantize_dynamic(
    model, {nn.Linear}, dtype=torch.qint8
)

# Save
torch.save(model_quantized.state_dict(), 'model_quantized.pt')
```

**ONNX Export** (faster inference):

```python
# Export to ONNX
dummy_input = torch.randint(0, 1000, (1, 256)).to(device)
dummy_mask = torch.ones(1, 256).to(device)

torch.onnx.export(
    model,
    (dummy_input, dummy_mask),
    'model.onnx',
    input_names=['input_ids', 'attention_mask'],
    output_names=['logits']
)
```

## üêõ Troubleshooting

### CUDA Out of Memory

```python
# Gi·∫£m batch size
BATCH_SIZE = 8  # Instead of 16

# Clear cache
torch.cuda.empty_cache()

# Gradient accumulation
accumulation_steps = 2
for i, batch in enumerate(train_loader):
    loss = loss / accumulation_steps
    loss.backward()

    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### Model kh√¥ng h·ªçc (loss kh√¥ng gi·∫£m)

1. Check learning rate (c√≥ th·ªÉ qu√° nh·ªè ho·∫∑c qu√° l·ªõn)
2. Check data (labels c√≥ ƒë√∫ng kh√¥ng?)
3. Try unfreeze BERT layers:
   ```python
   for param in model.bert.parameters():
       param.requires_grad = True
   ```

### Overfitting (train acc cao, val acc th·∫•p)

1. TƒÉng dropout: 0.3 ‚Üí 0.5
2. Data augmentation
3. Early stopping
4. Regularization (weight decay)

## üìö Resources

- **PhoBERT Paper:** https://arxiv.org/abs/2003.00744
- **Transformers Docs:** https://huggingface.co/docs/transformers
- **PyTorch Tutorial:** https://pytorch.org/tutorials/
- **Google Colab Tips:** https://colab.research.google.com/notebooks/

## ‚úÖ Checklist

- [ ] Setup Google Colab v·ªõi GPU
- [ ] Mount Google Drive
- [ ] Upload toxic detection dataset
- [ ] Train toxic detection model (10 epochs)
- [ ] Download toxic model checkpoint
- [ ] Upload emotion detection dataset
- [ ] Train emotion detection model (10 epochs)
- [ ] Download emotion model checkpoint
- [ ] Test both models v·ªõi examples
- [ ] Copy models v·ªÅ local project
- [ ] Start AI service v√† test API
- [ ] Integrate AI v√†o backend

---

**Ch√∫c b·∫°n training th√†nh c√¥ng! üöÄ**

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, h√£y check logs v√† error messages ƒë·ªÉ debug.
